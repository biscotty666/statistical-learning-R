---
title: "Classification"
format: 
  html:
    toc: true
    keep-md: true
  gfm: default
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(paged.print = FALSE)
```

```{r}
#| message: false
library(ISLR2)
library(ggplot2)
```

```{r}
names(Smarket)
dim(Smarket)
summary(Smarket)
```

```{r}
cor(Smarket[, -9])
```

```{r}
with(Smarket, plot(Volume))
```

```{r}
ggplot(Smarket, aes(
  x = 1:nrow(Smarket),
  y = Volume
)) +
  geom_point()
```

# Logistic Regression

Predict direction using lags amd Volume

```{r}
gml_fits <- glm(
  Direction ~ Lag1 + Lag2 +
    Lag3 + Lag4 + Lag5 + Volume,
  data = Smarket, family = binomial
)
summary(gml_fits)
```

```{r}
coef(gml_fits)
summary(gml_fits)$coef[, 4]
```

```{r}
glm_probs <- predict(gml_fits, type = "response")
glm_probs[1:10]
with(Smarket, contrasts(Direction))
```

```{r}
glm_pred <- rep("Down", 1250)
glm_pred[glm_probs > .5] <- "Up"
```

```{r}
table(glm_pred, Smarket$Direction)
with(Smarket, mean(glm_pred == Direction))
```

```{r}
attach(Smarket)
train <- (Year < 2005)
Smarket_2005 <- Smarket[!train, ]
dim(Smarket_2005)
Direction_2005 <- Direction[!train]
```

```{r}
train2 <- (Smarket$Year < 2005)
smarket_2005_2 <- Smarket[!train2, ]
dim(smarket_2005_2)
direction_2005_2 <- Smarket$Direction[!train2]
```

```{r}
glm_fits_2 <- glm(
  Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Volume,
  data = Smarket, family = binomial,
  subset = train
)
glm_probs_2 <- predict(glm_fits_2,
  Smarket_2005,
  type = "response"
)
```

```{r}
glm_pred_2 <- rep("Down", length(glm_probs_2))
glm_pred_2[glm_probs_2 > .5] <- "Up"
table(glm_pred_2, Direction_2005)
mean(glm_pred_2 == Direction_2005)
mean(glm_pred_2 != Direction_2005)
```

```{r}
glm_fits_3 <- glm(
  Direction ~ Lag1 + Lag2,
  data = Smarket, family = binomial,
  subset = train
)
glm_probs_3 <- predict(glm_fits_3,
  Smarket_2005,
  type = "response"
)

glm_pred_3 <- rep("Down", length(glm_probs_3))
glm_pred_3[glm_probs_3 > .5] <- "Up"
table(glm_pred_3, Direction_2005)
mean(glm_pred_3 == Direction_2005)
```

Suppose that we want to predict the returns associated with particular
values of Lag1 and Lag2. In particular, we want to predict Direction on a
day when Lag1 and Lag2 equal 1.2 and 1.1, respectively, and on a day when
they equal 1.5 and −0.8. We do this using the predict() function.

```{r}
predict(glm_fits_3,
  newdata = data.frame(
    Lag1 = c(1.2, 1.5),
    Lag2 = c(1.1, -0.8)
  ),
  type = "response"
)
```

# Linear Discriminant Analysis

```{r}
library(MASS)
lda_fit <- lda(
  Direction ~ Lag1 + Lag2,
  data = Smarket,
  subset = train
)
lda_fit
```

```{r}
plot(lda_fit)
```

The predict() function returns a list with three elements. The first ele-
ment, class, contains LDA’s predictions about the movement of the mar-
ket. The second element, posterior, is a matrix whose kth column contains
the posterior probability that the corresponding observation belongs to the kth class, computed from (4.15). Finally, x contains the linear discriminants, described earlier.

```{r}
lda_pred <- predict(lda_fit, Smarket_2005)
names(lda_pred)
```

```{r}
lda_class <- lda_pred$class
table(lda_class, Direction_2005)
mean(lda_class == Direction_2005)
```

```{r}
sum(lda_pred$posterior[, 1] >= .5)
sum(lda_pred$posterior[, 1] < .5)
```

Notice that the posterior probability output by the model corresponds to
the probability that the market will decrease

```{r}
lda_pred$posterior[1:20, 1]
lda_class[1:20]
```

Suppose that we wish to predict a market decrease only if we are very certain that the market will indeed decrease on that day—say, if the posterior probability is at least 90 %

```{r}
sum(lda_pred$posterior[, 1] > .9)
```

# Quadratic discriminant analysis

```{r}
qda_fit <- qda(
  Direction ~ Lag1 + Lag2,
  data = Smarket,
  subset = train
)
qda_fit
```

```{r}
qda_class <- predict(qda_fit, Smarket_2005)$class
table(qda_class, Direction_2005)
mean(qda_class == Direction_2005)
```

the QDA predictions are accurate almost 60 % of the time,
even though the 2005 data was not used to fit the model. This level of accu-
racy is quite impressive for stock market data, which is known to be quite
hard to model accurately. 

# Naive Bayes

```{r}
library(e1071)
nb_fit <- naiveBayes(
  Direction ~ Lag1 + Lag2,
  data = Smarket, subset = train
)
nb_fit
```

The output contains the estimated mean and standard deviation for each
variable in each class. For example, the mean for Lag1 is 0.0428 for
Direction=Down, and the standard deviation is 1.23. 

```{r}
mean(Lag1[train][Direction[train] == "Down"])
sd(Lag1[train][Direction[train] == "Down"])
```

```{r}
nb_class <- predict(nb_fit, Smarket_2005)
table(nb_class, Direction_2005)
mean(nb_class == Direction_2005)
```

Naive Bayes performs very well on this data, with accurate predictions over 59% of the time. This is slightly worse than QDA, but much better than LDA.

```{r}
nb_preds <- predict(nb_fit, Smarket_2005, type = "raw")
nb_preds[1:5, ]
```

# K-Nearest Neighbors

```{r}
library(class)
train_X <- cbind(Lag1, Lag2)[train, ]
test_X <- cbind(Lag1, Lag2)[!train, ]
train_direction <- Direction[train]
```

```{r}
set.seed(1)
knn_pred <- knn(train_X, test_X,
  train_direction,
  k = 1
)
table(knn_pred, Direction_2005)
(83 + 43) / 252
```

```{r}
knn_pred <- knn(train_X, test_X,
  train_direction,
  k = 3
)
table(knn_pred, Direction_2005)
mean(knn_pred == Direction_2005)
```

As an example we will apply the KNN approach to the Caravan data set, which is part of the ISLR2 library. This data set includes 85 predictors that measure demographic characteristics for 5,822 individuals. The response variable is Purchase, which indicates whether or not a given individual purchases a caravan insurance policy. In this data set, only 6% of people purchased caravan insurance.

```{r}
dim(Caravan)
summary(Caravan$Purchase)
348 / 5822
```

## Standardizing the variables

```{r}
standardized_X <- scale(Caravan[, -86])
var(Caravan[, 1])
var(Caravan[, 2])
var(standardized_X[, 1])
var(standardized_X[, 2])
```

```{r}
test <- 1:1000
train_X <- standardized_X[-test, ]
test_X <- standardized_X[test, ]
train_y <- Caravan$Purchase[-test]
test_y <- Caravan$Purchase[test]
```

```{r}
set.seed(1)
knn_pred <- knn(train_X, test_X,
  train_y,
  k = 1
)
mean(test_y != knn_pred) # Error rate
mean(test_y != "No")
```

At first glance, this may appear to be fairly good. However, since only 6 % of customers purchased insurance, we could get the error rate down to 6 % by always predicting No regardless of the values of the predictors!

What if the question is to identify those likely to purchase.

```{r}
table(knn_pred, test_y)
9 / (68 + 9)
```

Among 77 such customers, 9, or 11.7 %, actually do purchase insurance. This is double the rate that one would obtain from random guessing.

```{r}
knn_pred <- knn(train_X, test_X, train_y, k = 3)
table(knn_pred, test_y)
5 / 26
```

As a comparison, we can also fit a logistic regression model to the data. If we use 0.5 as the predicted probability cut-off for the classifier, then we have a problem: only seven of the test observations are predicted to purchase insurance. Even worse, we are wrong about all of these! However, we are not required to use a cut-off of 0.5. If we instead predict a purchase any time the predicted probability of purchase exceeds 0.25, we get much better results: we predict that 33 people will purchase insurance, and we are correct for about 33 % of these people. This is over five times better than random guessing!

```{r}
glm_fits <- glm(Purchase ~ .,
  data = Caravan,
  family = binomial,
  subset = -test
)
```
```{r}
glm_probs <- predict(glm_fits, Caravan[test, ],
  type = "response"
)
glm_pred <- rep("No", 1000)
glm_pred[glm_probs > .5] <- "Yes"
table(glm_pred, test_y)
```

```{r}
glm_pred <- rep("No", 1000)
glm_pred[glm_probs > .25] <- "Yes"
table(glm_pred, test_y)
11 / (22 + 11)
```

# Poisson regression

Finally, we fit a Poisson regression model to the Bikeshare data set, which measures the number of bike rentals (bikers) per hour in Washington, DC. The data can be found in the ISLR2 library.

```{r}
dim(Bikeshare)
names(Bikeshare)
```

```{r}
mod_lm <- lm(
  bikers ~ mnth + hr + workingday + temp + weathersit,
  data = Bikeshare
)
summary(mod_lm)
```

Times are relative to the baseline, eg. 16.55 more riders in the month of March compared to January.

```{r}
contrasts(Bikeshare$hr) <- contr.sum(24)
contrasts(Bikeshare$mnth) <- contr.sum(12)
mod_lm2 <- lm(
  bikers ~ mnth + hr + workingday + temp + weathersit,
  data = Bikeshare
)
summary(mod_lm2)
```

Coefficients are differences from the mean and always sum to zero. There are 46 fewer riders in Jan than on average, all other things being equal.

Coding doesn't matter as long as the results are interpreted properly. Sum of squared differences is the same.

```{r}
sum((predict(mod_lm) - predict(mod_lm2))^2)
```

```{r}
all.equal(predict(mod_lm), predict(mod_lm2))
```

```{r}
coef_months <- c(
  coef(mod_lm2)[2:12],
  -sum(coef(mod_lm2)[2:12])
)
```

```{r}
plot(coef_months,
  xlab = "Month", ylab = "Coefficient",
  xaxt = "n", col = "blue", pch = 19, type = "o"
)
axis(side = 1, at = 1:12, labels = c(
  "J", "F", "M", "A",
  "M", "J", "J", "A", "S", "O", "N", "D"
))
```

```{r}
coef_hours <- c(coef(mod_lm2)[13:35] - sum(coef(mod_lm2)[13:35]))

plot(coef_hours,
  xlab = "Hour", ylab = "Coefficient",
  col = "blue", pch = 19, type = "o"
)
```

> Now, fitting a Poisson model

```{r}
mod_pois <- glm(
  bikers ~ mnth + hr + workingday + temp + weathersit,
  data = Bikeshare,
  family = poisson
)
summary(mod_pois)
```

```{r}
coef_mnth <- c(
  coef(mod_pois)[2:12],
  -sum(coef(mod_pois)[2:12])
)
plot(coef_mnth,
  xlab = "Month", ylab = "Coefficient",
  xaxt = "n", col = "blue", pch = 19, type = "o"
)
axis(side = 1, at = 1:12, labels = c(
  "J", "F", "M", "A", "M", "J",
  "J", "A", "S", "O", "N", "D"
))
```

```{r}
coef_hours <- c(
  coef(mod_pois)[13:35],
  -sum(coef(mod_pois)[13:35])
)
plot(coef_hours,
  xlab = "Hour", ylab = "Coefficient",
  col = "blue", pch = 19, type = "o"
)
```

```{r}
plot(predict(mod_lm2), predict(mod_pois, type = "response"))
abline(0, 1, col = 2, lwd = 3)
```




















