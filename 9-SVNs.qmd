---
title: "Support Vector Machines"
format: 
  html:
    toc: true
    keep-md: true
  gfm: default
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(paged.print = FALSE)
options(digits = 4)
```

# Support Vector Classifier

When the cost argument is small, then the margins will be wide and many support vectors will be on the margin or will violate the margin. When the cost argument is large, then the margins will be narrow and there will be few support vectors on the margin or violating the margin.

```{r}
set.seed(1)
x <- matrix(rnorm(20 * 2), ncol = 2)
y <- c(rep(-1, 10), rep(1, 10))
x[y == 1, ] <- x[y == 1, ] + 1
plot(x, col = (3 - y))
```

They are not linearly separable.

For classification, response variable must be a factor.

```{r}
dat <- data.frame(
  x = x,
  y = as.factor(y)
)
library(e1071)
svmfit <- svm(
  y ~ .,
  data = dat, kernel = "linear", cost = 10, scale = FALSE
)
```

```{r}
plot(svmfit, dat)
```

The support vectors

```{r}
svmfit$index
```

```{r}
summary(svmfit)
```

with a smaller cost

```{r}
svmfit <- svm(
  y ~ .,
  data = dat, kernel = "linear", cost = 0.1, scale = FALSE
)
plot(svmfit, dat)
```

```{r}
svmfit$index
```

Cross-validate

```{r}
set.seed(1)
tune_out <- tune(
  svm, y ~ .,
  data = dat, kernel = "linear",
  ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100))
)
```

```{r}
summary(tune_out)
```

`cost=0.1` has the lowest error rate. The best model is stored.

```{r}
best_mod <- tune_out$best.model
summary(best_mod)
```

Generate test set data

```{r}
xtest <- matrix(rnorm(40), ncol = 2)
ytest <- sample(c(-1, 1), 20, rep = T)
xtest[ytest == 1, ] <- xtest[ytest == 1, ] + 1
testdat <- data.frame(x = xtest, y = as.factor(ytest))
```

```{r}
ypred <- predict(best_mod, testdat)
table(predict = ypred, truth = testdat$y)
```

17 out of 20 are correctly classified.

Using cost = 0.01 is worse

```{r}
svmfit <- svm(y ~ .,
  data = dat, kernel = "linear",
  cost = 0.01, scale = F
)
ypred <- predict(svmfit, truth = testdat$y)
table(predict = ypred, truth = testdat$y)
```

> Consider when two classes are linearly separable: use `svm()` to find the hyperplane

```{r}
x[y == 1, ] <- x[y == 1, ] + 0.5
plot(x, col = (y + 5) / 2, pch = 19)
```

```{r}
dat <- data.frame(x = x, y = as.factor(y))
svmfit <- svm(y ~ ., data = dat, kernel = "linear", cost = 1e5)
summary(svmfit)
```

```{r}
plot(svmfit, dat)
```

The margin is very narrow, and will likely perform poorly on test data.

```{r}
svmfit <- svm(y ~ ., data = dat, kernel = "linear", cost = 1)
summary(svmfit)
```

```{r}
plot(svmfit, dat)
```

One training error is misclassified but the margin is much wider.

# Support Vector Machine

Use `kernel = "polynomial"` or `kernel = "radial"`

```{r}
set.seed(1)
x <- matrix(rnorm(200 * 2), ncol = 2)
x[1:100, ] <- x[1:100, ] + 2
x[101:150, ] <- x[101:150, ] - 2
y <- c(rep(1, 150), rep(2, 50))
dat <- data.frame(x = x, y = as.factor(y))
plot(x, col = y)
```

```{r}
train <- sample(200, 100)
svmfit <- svm(y ~ .,
  data = dat[train, ], kernel = "radial",
  gamma = 1, cost = 1
)
plot(svmfit, dat[train, ])
```

```{r}
summary(svmfit)
```

```{r}
svmfit <- svm(y ~ .,
  data = dat[train, ], kernel = "radial",
  gamma = 0.5, cost = 1
)
plot(svmfit, dat[train, ])
```


```{r}
svmfit <- svm(y ~ .,
  data = dat[train, ], kernel = "radial",
  gamma = 1, cost = 1e2
)
plot(svmfit, dat[train, ])
```

```{r}
svmfit <- svm(y ~ .,
  data = dat[train, ], kernel = "radial",
  gamma = 1, cost = 1e5
)
plot(svmfit, dat[train, ])
```

> Cross-validation

```{r}
set.seed(1)
tune_out <- tune(svm, y ~ .,
  data = dat[train, ],
  kernel = "radial",
  ranges = list(
    cost = c(0.1, 1, 10, 100, 1000, 10000),
    gamma = c(0.5, 1, 2, 3, 4, 5)
  )
)
summary(tune_out)
```

```{r}
table(
  true = dat[-train, "y"],
  pred = predict(
    tune_out$best.model,
    newdata = dat[-train, ]
  )
)
```

```{r}
26 / (26 + 74)
```

# ROC Curves

```{r}
library(ROCR)
roc_plot <- function(pred, truth, ...) {
  predob <- prediction(pred, truth)
  perf <- performance(predob, "tpr", "fpr")
  plot(perf, ...)
}
```

Optain fitted vaules

```{r}
svmfit_opt <- svm(y ~ .,
  data = dat[train, ],
  kernel = "radial", gamma = .5, cost = 1,
  decision.values = T
)
fitted <- attributes(
  predict(svmfit_opt, dat[train, ], decision.values = T)
)$decision.values
```

```{r}
par(mfrow = c(1, 2))
roc_plot(-fitted, dat[train, "y"], main = "Training Data")
```

```{r}
par(mfrow = c(1, 2))
roc_plot(-fitted, dat[train, "y"], main = "Training Data")
svmfit_flex <- svm(y ~ .,
  data = dat[train, ], kernel = "radial",
  gamma = 50, cost = 1, decision.values = T
)
fitted <- attributes(
  predict(svmfit_flex, dat[train, ], decision.values = T)
)$decision.values
roc_plot(-fitted, dat[train, "y"], add = T, col = "red")
fitted <- attributes(
  predict(svmfit_flex, dat[-train, ], decision.values = T)
)$decision.values
roc_plot(-fitted, dat[-train, "y"], main = "Test Data")
fitted <- attributes(
  predict(svmfit_flex, dat[-train, ], decision.values = T)
)$decision.values
roc_plot(-fitted, dat[-train, "y"], add = T, col = "red")
```

# Multi-class SVM

> One-versus-one

Generate a third class of observations


```{r}
set.seed(1)
x <- rbind(x, matrix(rnorm(50 * 2), ncol = 2))
y <- c(y, rep(0, 50))
x[y == 0, 2] <- x[y == 0, 2] + 2
par(mfrow = c(1, 1))
plot(x, col = (y + 1))
```

```{r}
svmfit <- svm(y ~ .,
  data = dat, kernel = "radial",
  cost = 10, gamma = 1
)
plot(svmfit, dat)
```

# Application to Gene Expression Data

We now examine the Khan data set, which consists of a number of tissue samples corresponding to four distinct types of small round blue cell tumors. For each tissue sample, gene expression measurements are available. The data set consists of training data, xtrain and ytrain, and testing data, xtest and ytest.

```{r}
library(ISLR2)
names(Khan)
dim(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
```

```{r}
table(Khan$ytrain)
table(Khan$ytest)
```

Many features compared to observations suggests a linear kernel as additional flexibility is usually not needed

```{r}
dat <- data.frame(
  x = Khan$xtrain,
  y = as.factor(Khan$ytrain)
)
out <- svm(y ~ ., data = dat, kernel = "linear", cost = 10)
summary(out)
table(out$fitted, dat$y)
```

No training data errors. Expected due to the large number of variables relative to observations.

```{r}
dat_test <- data.frame(
  x = Khan$xtest,
  y = as.factor(Khan$ytest)
)
pred_test <- predict(out, newdata = dat_test)
table(pred_test, dat_test$y)
```

Two errors occur



















